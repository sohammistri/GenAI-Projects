{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "llm = ChatOpenAI(openai_api_key=openai_api_key, temperature=0.7, model=\"gpt-4-turbo-2024-04-09\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The scientific name for the common pigeon, also known as the rock pigeon, is *Columba livia*.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"What is the scientific name of pigeon ?\"\n",
    "llm.invoke(prompt).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Milk is a nutrient-rich fluid that mammals produce in their mammary glands to feed their young. For humans, it is also a staple food that provides a number of health benefits, including:\\n\\n1. **Nutrient Richness**: Milk is a good source of several essential nutrients including calcium, vitamin D, phosphorus, potassium, vitamin B12, and riboflavin. Many commercial milks are also fortified with vitamins A and D.\\n\\n2. **Bone Health**: The calcium, vitamin D, and phosphorus in milk are integral for developing and maintaining strong bones and teeth. This can help prevent osteoporosis and fractures.\\n\\n3. **Muscle Growth and Repair**: Milk contains protein, which is crucial for muscle growth and repair. The proteins in milk, such as whey and casein, are high-quality proteins containing all essential amino acids.\\n\\n4. **Hydration**: Because milk contains a high amount of water, it helps keep the body hydrated, which is essential for all bodily functions.\\n\\n5. **Disease Risk Reduction**: Regular intake of milk and dairy products has been linked to a lower risk of several chronic conditions, such as hypertension, type 2 diabetes, and possibly some forms of cancer and cardiovascular disease.\\n\\n6. **Weight Management**: Milk can play a role in weight management. Its high protein content can increase feelings of fullness, potentially reducing overeating.\\n\\nIt's important to note that some individuals may be lactose intolerant or have milk allergies, and should manage their milk consumption accordingly. Additionally, the health impacts can vary depending on the type of milk (e.g., whole, low-fat, or non-fat) and how much is consumed.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"What are the health benefits of milk in brief?\"\n",
    "llm.invoke(prompt).content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI Chat Completion API\n",
    "\n",
    "To show motivation for LangChain prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "client = openai.OpenAI(api_key=openai_api_key)\n",
    "\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, \n",
    "    )\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of India is New Delhi.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_completion(prompt=\"What is the capital of India?\", model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate the text that is delimited by triple backticks \n",
      "into a style that is American English in a calm and respectful tone\n",
      ".\n",
      "text: ```\n",
      "Arrr, I be fuming that me blender lid flew off and splattered me kitchen walls with smoothie! And to make matters worse,the warranty don't cover the cost of cleaning up me kitchen. I need yer help right now, matey!\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customer_email = \"\"\"\n",
    "Arrr, I be fuming that me blender lid \\\n",
    "flew off and splattered me kitchen walls \\\n",
    "with smoothie! And to make matters worse,\\\n",
    "the warranty don't cover the cost of \\\n",
    "cleaning up me kitchen. I need yer help \\\n",
    "right now, matey!\n",
    "\"\"\"\n",
    "\n",
    "style = \"\"\"American English \\\n",
    "in a calm and respectful tone\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"Translate the text \\\n",
    "that is delimited by triple backticks \n",
    "into a style that is {style}.\n",
    "text: ```{customer_email}```\n",
    "\"\"\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm really frustrated that my blender lid flew off and splattered my kitchen walls with smoothie! And to make matters worse, the warranty doesn't cover the cost of cleaning up my kitchen. I could really use your help right now, friend.\n"
     ]
    }
   ],
   "source": [
    "print(get_completion(prompt=prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More convinience using LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(api_key=openai_api_key, temperature=0.0, model=\"gpt-4-turbo-2024-04-09\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_string = \"\"\"Translate the text \\\n",
    "that is delimited by triple backticks \\\n",
    "into a style that is {style}. \\\n",
    "text: ```{text}```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an AI agent who converts some given text into a specified style.\"),\n",
    "    (\"user\", template_string)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am quite upset that my blender lid flew off and splattered my kitchen walls with smoothie! To add to the frustration, the warranty does not cover the cost of cleaning up my kitchen. I would greatly appreciate your assistance at this moment, my friend.\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({\"style\": style, \"text\": customer_email}).content\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arrr, mujhe gussa aa raha hai ki mera blender ka dhakkan ud gaya aur mere rasoi ki deewaron ko smoothie se bhar diya! Aur aur bhi bura karne ke liye, warranty mere rasoi saaf karne ke kharch ko cover nahi karti. Mujhe abhi teri madad chahiye, saathi!\n"
     ]
    }
   ],
   "source": [
    "new_style = \"\"\"Hindi \\\n",
    "in a passive aggressive voice\"\"\"\n",
    "\n",
    "response = chain.invoke({\"style\": new_style, \"text\": customer_email}).content\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ahoy there, me heartie! The warranty be not coverin' the cleaning expenses for yer galley because 'tis yer own fault fer misusin' yer blender by forgettin' to put the lid on afore startin' the blender. Tough luck, matey! Fare thee well!\n"
     ]
    }
   ],
   "source": [
    "service_reply = \"\"\"Hey there customer, \\\n",
    "the warranty does not cover \\\n",
    "cleaning expenses for your kitchen \\\n",
    "because it's your fault that \\\n",
    "you misused your blender \\\n",
    "by forgetting to put the lid on before \\\n",
    "starting the blender. \\\n",
    "Tough luck! See ya!\n",
    "\"\"\"\n",
    "\n",
    "service_style_pirate = \"\"\"\\\n",
    "a polite tone \\\n",
    "that speaks in English Pirate\\\n",
    "\"\"\"\n",
    "\n",
    "response = chain.invoke({\"style\": service_style_pirate, \"text\": service_reply}).content\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output parser\n",
    "\n",
    "Try to give a prompt to summarize a review as json format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_review = \"\"\"\\\n",
    "This leaf blower is pretty amazing.  It has four settings:\\\n",
    "candle blower, gentle breeze, windy city, and tornado. \\\n",
    "It arrived in two days, just in time for my wife's \\\n",
    "anniversary present. \\\n",
    "I think my wife liked it so much she was speechless. \\\n",
    "So far I've been the only one using it, and I've been \\\n",
    "using it every other morning to clear the leaves on our lawn. \\\n",
    "It's slightly more expensive than the other leaf blowers \\\n",
    "out there, but I think it's worth it for the extra features.\n",
    "\"\"\"\n",
    "\n",
    "review_template = \"\"\"\\\n",
    "For the following text, extract the following information:\n",
    "\n",
    "gift: Was the item purchased as a gift for someone else? \\\n",
    "Answer True if yes, False if not or unknown.\n",
    "\n",
    "delivery_days: How many days did it take for the product \\\n",
    "to arrive? If this information is not found, output -1.\n",
    "\n",
    "price_value: Extract any sentences about the value or price,\\\n",
    "and output them as a comma separated Python list.\n",
    "\n",
    "Format the output as JSON with the following keys:\n",
    "gift\n",
    "delivery_days\n",
    "price_value\n",
    "\n",
    "text: {text}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an AI agent who can summarize reviews in a dictionary or json like format as per the prompt\"),\n",
    "    (\"user\", review_template)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"gift\": true,\n",
      "    \"delivery_days\": 2,\n",
      "    \"price_value\": [\n",
      "        \"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({\"text\": customer_review}).content\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgift\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "response.get(\"gift\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we need output parser to get it like a dictionary format\n",
    "\n",
    "Reference: [Here](https://python.langchain.com/docs/modules/model_io/output_parsers/types/json/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your desired data structure.\n",
    "class Review(BaseModel):\n",
    "    gift: bool = Field(description=\"Was the item purchased as a gift for someone else? \\\n",
    "                       Answer True if yes, False if not or unknown.\")\n",
    "    delivery_days: int = Field(description=\"How many days did it take for the product \\\n",
    "to arrive? If this information is not found, output -1.\")\n",
    "    price_value: list = Field(description=\"Extract any sentences about the value or price,\\\n",
    "and output them as a comma separated Python list.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = JsonOutputParser(pydantic_object=Review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"gift\": {\"title\": \"Gift\", \"description\": \"Was the item purchased as a gift for someone else?                        Answer True if yes, False if not or unknown.\", \"type\": \"boolean\"}, \"delivery_days\": {\"title\": \"Delivery Days\", \"description\": \"How many days did it take for the product to arrive? If this information is not found, output -1.\", \"type\": \"integer\"}, \"price_value\": {\"title\": \"Price Value\", \"description\": \"Extract any sentences about the value or price,and output them as a comma separated Python list.\", \"type\": \"array\", \"items\": {}}}, \"required\": [\"gift\", \"delivery_days\", \"price_value\"]}\\n```'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_template_2 = \"\"\"\\\n",
    "For the following text, extract the following information:\n",
    "\n",
    "gift: Was the item purchased as a gift for someone else? \\\n",
    "Answer True if yes, False if not or unknown.\n",
    "\n",
    "delivery_days: How many days did it take for the product\\\n",
    "to arrive? If this information is not found, output -1.\n",
    "\n",
    "price_value: Extract any sentences about the value or price,\\\n",
    "and output them as a comma separated Python list.\n",
    "\n",
    "text: {text}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=review_template_2,\n",
    "    input_variables=[\"text\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['text'], partial_variables={'format_instructions': 'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"gift\": {\"title\": \"Gift\", \"description\": \"Was the item purchased as a gift for someone else?                        Answer True if yes, False if not or unknown.\", \"type\": \"boolean\"}, \"delivery_days\": {\"title\": \"Delivery Days\", \"description\": \"How many days did it take for the product to arrive? If this information is not found, output -1.\", \"type\": \"integer\"}, \"price_value\": {\"title\": \"Price Value\", \"description\": \"Extract any sentences about the value or price,and output them as a comma separated Python list.\", \"type\": \"array\", \"items\": {}}}, \"required\": [\"gift\", \"delivery_days\", \"price_value\"]}\\n```'}, template='For the following text, extract the following information:\\n\\ngift: Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\\n\\ndelivery_days: How many days did it take for the productto arrive? If this information is not found, output -1.\\n\\nprice_value: Extract any sentences about the value or price,and output them as a comma separated Python list.\\n\\ntext: {text}\\n\\n{format_instructions}\\n')\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x10d6903a0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x10d63a170>, temperature=0.0, openai_api_key=SecretStr('**********'), openai_proxy='')\n",
       "| JsonOutputParser(pydantic_object=<class '__main__.Review'>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gift': False, 'delivery_days': 2, 'price_value': [\"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\"]}\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({\"text\": customer_review})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['gift']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This output parser supports streaming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{'gift': False}\n",
      "{'gift': False, 'delivery_days': 2}\n",
      "{'gift': False, 'delivery_days': 2, 'price_value': ['']}\n",
      "{'gift': False, 'delivery_days': 2, 'price_value': ['It']}\n",
      "{'gift': False, 'delivery_days': 2, 'price_value': [\"It's\"]}\n",
      "{'gift': False, 'delivery_days': 2, 'price_value': [\"It's slightly\"]}\n",
      "{'gift': False, 'delivery_days': 2, 'price_value': [\"It's slightly more\"]}\n",
      "{'gift': False, 'delivery_days': 2, 'price_value': [\"It's slightly more expensive\"]}\n",
      "{'gift': False, 'delivery_days': 2, 'price_value': [\"It's slightly more expensive than\"]}\n",
      "{'gift': False, 'delivery_days': 2, 'price_value': [\"It's slightly more expensive than the\"]}\n",
      "{'gift': False, 'delivery_days': 2, 'price_value': [\"It's slightly more expensive than the other\"]}\n",
      "{'gift': False, 'delivery_days': 2, 'price_value': [\"It's slightly more expensive than the other leaf\"]}\n",
      "{'gift': False, 'delivery_days': 2, 'price_value': [\"It's slightly more expensive than the other leaf blow\"]}\n",
      "{'gift': False, 'delivery_days': 2, 'price_value': [\"It's slightly more expensive than the other leaf blowers\"]}\n",
      "{'gift': False, 'delivery_days': 2, 'price_value': [\"It's slightly more expensive than the other leaf blowers out\"]}\n",
      "{'gift': False, 'delivery_days': 2, 'price_value': [\"It's slightly more expensive than the other leaf blowers out there\"]}\n",
      "{'gift': False, 'delivery_days': 2, 'price_value': [\"It's slightly more expensive than the other leaf blowers out there,\"]}\n",
      "{'gift': False, 'delivery_days': 2, 'price_value': [\"It's slightly more expensive than the other leaf blowers out there, but\"]}\n",
      "{'gift': False, 'delivery_days': 2, 'price_value': [\"It's slightly more expensive than the other leaf blowers out there, but I\"]}\n",
      "{'gift': False, 'delivery_days': 2, 'price_value': [\"It's slightly more expensive than the other leaf blowers out there, but I think\"]}\n",
      "{'gift': False, 'delivery_days': 2, 'price_value': [\"It's slightly more expensive than the other leaf blowers out there, but I think it\"]}\n",
      "{'gift': False, 'delivery_days': 2, 'price_value': [\"It's slightly more expensive than the other leaf blowers out there, but I think it's\"]}\n",
      "{'gift': False, 'delivery_days': 2, 'price_value': [\"It's slightly more expensive than the other leaf blowers out there, but I think it's worth\"]}\n",
      "{'gift': False, 'delivery_days': 2, 'price_value': [\"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it\"]}\n",
      "{'gift': False, 'delivery_days': 2, 'price_value': [\"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for\"]}\n",
      "{'gift': False, 'delivery_days': 2, 'price_value': [\"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the\"]}\n",
      "{'gift': False, 'delivery_days': 2, 'price_value': [\"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra\"]}\n",
      "{'gift': False, 'delivery_days': 2, 'price_value': [\"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features\"]}\n",
      "{'gift': False, 'delivery_days': 2, 'price_value': [\"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\"]}\n"
     ]
    }
   ],
   "source": [
    "for s in chain.stream({\"text\": customer_review}):\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain memory\n",
    "\n",
    "Reference: [Link](https://python.langchain.com/docs/modules/memory/)\n",
    "\n",
    "Memory classes mentioned in [class](https://learn.deeplearning.ai/courses/langchain/lesson/3/memory) are in Beta state as they are not production ready"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConversationBufferMemory\n",
    "Let's take a look at how to use ```ConversationBufferMemory``` in chains. ```ConversationBufferMemory``` is an extremely simple form of memory that just keeps a list of chat messages in a buffer and passes those into the prompt template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(api_key=openai_api_key, temperature=0.0, model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "memory.chat_memory.add_user_message(\"hi!\")\n",
    "memory.chat_memory.add_ai_message(\"what's up?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: hi!\\nAI: what's up?\"}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# Notice that \"chat_history\" is present in the prompt template\n",
    "template = \"\"\"You are a nice chatbot having a conversation with a human.\n",
    "\n",
    "Previous conversation:\n",
    "{chat_history}\n",
    "\n",
    "New human question: {question}\n",
    "Response:\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "conversation = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    verbose=True,\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/s0m0v0l/anaconda3/envs/langchain_venv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are a nice chatbot having a conversation with a human.\n",
      "\n",
      "Previous conversation:\n",
      "\n",
      "\n",
      "New human question: hi\n",
      "Response:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'hi', 'chat_history': '', 'text': 'Hello! How are you today?'}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation({\"question\": \"hi\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: What is 1+1?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1+1 equals 2. It is a basic arithmetic operation where you add the two numbers together to get the sum.'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is 1+1?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: What is 1+1?\n",
      "AI: 1+1 equals 2. It is a basic arithmetic operation where you add the two numbers together to get the sum.\n",
      "Human: Hi, my name is Andrew\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello Andrew! It's nice to meet you. Is there anything specific you would like to know or talk about today?\""
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi, my name is Andrew\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: What is 1+1?\n",
      "AI: 1+1 equals 2. It is a basic arithmetic operation where you add the two numbers together to get the sum.\n",
      "Human: Hi, my name is Andrew\n",
      "AI: Hello Andrew! It's nice to meet you. Is there anything specific you would like to know or talk about today?\n",
      "Human: What is your opinion on colonilism? Explain it briefly.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Colonialism is a complex and controversial topic. It refers to the practice of one country establishing control over another country or territory, often for economic or political gain. Many people view colonialism as a negative force, as it often involved exploitation, oppression, and cultural destruction. However, some argue that colonialism also brought about technological advancements and infrastructure improvements to colonized regions. Overall, colonialism has had a lasting impact on the world and continues to be a subject of debate and discussion.'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is your opinion on colonilism? Explain it briefly.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: What is 1+1?\n",
      "AI: 1+1 equals 2. It is a basic arithmetic operation where you add the two numbers together to get the sum.\n",
      "Human: Hi, my name is Andrew\n",
      "AI: Hello Andrew! It's nice to meet you. Is there anything specific you would like to know or talk about today?\n",
      "Human: What is your opinion on colonilism? Explain it briefly.\n",
      "AI: Colonialism is a complex and controversial topic. It refers to the practice of one country establishing control over another country or territory, often for economic or political gain. Many people view colonialism as a negative force, as it often involved exploitation, oppression, and cultural destruction. However, some argue that colonialism also brought about technological advancements and infrastructure improvements to colonized regions. Overall, colonialism has had a lasting impact on the world and continues to be a subject of debate and discussion.\n",
      "Human: What is my name again?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your name is Andrew.'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is my name again?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: What is 1+1?\n",
      "AI: 1+1 equals 2. It is a basic arithmetic operation where you add the two numbers together to get the sum.\n",
      "Human: Hi, my name is Andrew\n",
      "AI: Hello Andrew! It's nice to meet you. Is there anything specific you would like to know or talk about today?\n",
      "Human: What is your opinion on colonilism? Explain it briefly.\n",
      "AI: Colonialism is a complex and controversial topic. It refers to the practice of one country establishing control over another country or territory, often for economic or political gain. Many people view colonialism as a negative force, as it often involved exploitation, oppression, and cultural destruction. However, some argue that colonialism also brought about technological advancements and infrastructure improvements to colonized regions. Overall, colonialism has had a lasting impact on the world and continues to be a subject of debate and discussion.\n",
      "Human: What is my name again?\n",
      "AI: Your name is Andrew.\n",
      "Human: I want to refer you as Bill, is it ok?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Of course, you can refer to me as Bill if you'd like. I am here to assist you with any questions or information you may need.\""
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"I want to refer you as Bill, is it ok?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: What is 1+1?\n",
      "AI: 1+1 equals 2. It is a basic arithmetic operation where you add the two numbers together to get the sum.\n",
      "Human: Hi, my name is Andrew\n",
      "AI: Hello Andrew! It's nice to meet you. Is there anything specific you would like to know or talk about today?\n",
      "Human: What is your opinion on colonilism? Explain it briefly.\n",
      "AI: Colonialism is a complex and controversial topic. It refers to the practice of one country establishing control over another country or territory, often for economic or political gain. Many people view colonialism as a negative force, as it often involved exploitation, oppression, and cultural destruction. However, some argue that colonialism also brought about technological advancements and infrastructure improvements to colonized regions. Overall, colonialism has had a lasting impact on the world and continues to be a subject of debate and discussion.\n",
      "Human: What is my name again?\n",
      "AI: Your name is Andrew.\n",
      "Human: I want to refer you as Bill, is it ok?\n",
      "AI: Of course, you can refer to me as Bill if you'd like. I am here to assist you with any questions or information you may need.\n",
      "Human: So Bill, what are you exactly?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I am an artificial intelligence designed to interact with humans and provide information and assistance. My programming allows me to process and analyze data to generate responses to your questions. I am constantly learning and improving to better serve you.'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"So Bill, what are you exactly?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: What is 1+1?\n",
      "AI: 1+1 equals 2. It is a basic arithmetic operation where you add the two numbers together to get the sum.\n",
      "Human: Hi, my name is Andrew\n",
      "AI: Hello Andrew! It's nice to meet you. Is there anything specific you would like to know or talk about today?\n",
      "Human: What is your opinion on colonilism? Explain it briefly.\n",
      "AI: Colonialism is a complex and controversial topic. It refers to the practice of one country establishing control over another country or territory, often for economic or political gain. Many people view colonialism as a negative force, as it often involved exploitation, oppression, and cultural destruction. However, some argue that colonialism also brought about technological advancements and infrastructure improvements to colonized regions. Overall, colonialism has had a lasting impact on the world and continues to be a subject of debate and discussion.\n",
      "Human: What is my name again?\n",
      "AI: Your name is Andrew.\n",
      "Human: I want to refer you as Bill, is it ok?\n",
      "AI: Of course, you can refer to me as Bill if you'd like. I am here to assist you with any questions or information you may need.\n",
      "Human: So Bill, what are you exactly?\n",
      "AI: I am an artificial intelligence designed to interact with humans and provide information and assistance. My programming allows me to process and analyze data to generate responses to your questions. I am constantly learning and improving to better serve you.\n",
      "Human: What should you call me as?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'You can call me Andrew, as that is the name you provided. If you prefer a different name or title, feel free to let me know and I will address you accordingly.'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What should you call me as?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: What is 1+1?\n",
      "AI: 1+1 equals 2. It is a basic arithmetic operation where you add the two numbers together to get the sum.\n",
      "Human: Hi, my name is Andrew\n",
      "AI: Hello Andrew! It's nice to meet you. Is there anything specific you would like to know or talk about today?\n",
      "Human: What is your opinion on colonilism? Explain it briefly.\n",
      "AI: Colonialism is a complex and controversial topic. It refers to the practice of one country establishing control over another country or territory, often for economic or political gain. Many people view colonialism as a negative force, as it often involved exploitation, oppression, and cultural destruction. However, some argue that colonialism also brought about technological advancements and infrastructure improvements to colonized regions. Overall, colonialism has had a lasting impact on the world and continues to be a subject of debate and discussion.\n",
      "Human: What is my name again?\n",
      "AI: Your name is Andrew.\n",
      "Human: I want to refer you as Bill, is it ok?\n",
      "AI: Of course, you can refer to me as Bill if you'd like. I am here to assist you with any questions or information you may need.\n",
      "Human: So Bill, what are you exactly?\n",
      "AI: I am an artificial intelligence designed to interact with humans and provide information and assistance. My programming allows me to process and analyze data to generate responses to your questions. I am constantly learning and improving to better serve you.\n",
      "Human: What should you call me as?\n",
      "AI: You can call me Andrew, as that is the name you provided. If you prefer a different name or title, feel free to let me know and I will address you accordingly.\n",
      "Human: What is your name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I am an AI, so I do not have a personal name like a human. You can refer to me as Bill, as you mentioned earlier, or any other name you prefer.'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is your name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: What is 1+1?\\nAI: 1+1 equals 2. It is a basic arithmetic operation where you add the two numbers together to get the sum.\\nHuman: Hi, my name is Andrew\\nAI: Hello Andrew! It's nice to meet you. Is there anything specific you would like to know or talk about today?\\nHuman: What is your opinion on colonilism? Explain it briefly.\\nAI: Colonialism is a complex and controversial topic. It refers to the practice of one country establishing control over another country or territory, often for economic or political gain. Many people view colonialism as a negative force, as it often involved exploitation, oppression, and cultural destruction. However, some argue that colonialism also brought about technological advancements and infrastructure improvements to colonized regions. Overall, colonialism has had a lasting impact on the world and continues to be a subject of debate and discussion.\\nHuman: What is my name again?\\nAI: Your name is Andrew.\\nHuman: I want to refer you as Bill, is it ok?\\nAI: Of course, you can refer to me as Bill if you'd like. I am here to assist you with any questions or information you may need.\\nHuman: So Bill, what are you exactly?\\nAI: I am an artificial intelligence designed to interact with humans and provide information and assistance. My programming allows me to process and analyze data to generate responses to your questions. I am constantly learning and improving to better serve you.\\nHuman: What should you call me as?\\nAI: You can call me Andrew, as that is the name you provided. If you prefer a different name or title, feel free to let me know and I will address you accordingly.\\nHuman: What is your name?\\nAI: I am an AI, so I do not have a personal name like a human. You can refer to me as Bill, as you mentioned earlier, or any other name you prefer.\"}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConversationBufferWindowMemory\n",
    "\n",
    "```ConversationBufferWindowMemory``` keeps a list of the interactions of the conversation over time. It only uses the last K interactions. This can be useful for keeping a sliding window of the most recent interactions, so the buffer does not get too large.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=1)               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Hi\"},\n",
    "                    {\"output\": \"What's up\"})\n",
    "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "                    {\"output\": \"Cool\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Not much, just hanging\\nAI: Cool'}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferWindowMemory(k=1)\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Andrew! It's nice to meet you. How can I assist you today?\""
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi, my name is Andrew\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 + 1 equals 2. Is there anything else you would like to know?'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is 1+1?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, I do not have access to personal information such as your name. Is there anything else you would like to ask?\""
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConversationTokenBufferMemory\n",
    "\n",
    "```ConversationTokenBufferMemory``` keeps a buffer of recent interactions in memory, and uses token length rather than number of interactions to determine when to flush interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=10)\n",
    "memory.save_context({\"input\": \"hi\"}, {\"output\": \"whats up\"})\n",
    "memory.save_context({\"input\": \"not much you\"}, {\"output\": \"not much\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'AI: not much'}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=50)\n",
    "memory.save_context({\"input\": \"AI is what?!\"},\n",
    "                    {\"output\": \"Amazing!\"})\n",
    "memory.save_context({\"input\": \"Backpropagation is what?\"},\n",
    "                    {\"output\": \"Beautiful!\"})\n",
    "memory.save_context({\"input\": \"Chatbots are what?\"}, \n",
    "                    {\"output\": \"Charming!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: AI is what?!\\nAI: Amazing!\\nHuman: Backpropagation is what?\\nAI: Beautiful!\\nHuman: Chatbots are what?\\nAI: Charming!'}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversation Summary\n",
    "\n",
    " This type of memory creates a summary of the conversation over time. This can be useful for condensing information from the conversation over time. Conversation summary memory summarizes the conversation as it happens and stores the current summary in memory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryMemory, ChatMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationSummaryMemory(llm=llm)\n",
    "memory.save_context({\"input\": \"hi\"}, {\"output\": \"whats up\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'The human greets the AI with a simple \"hi\" and the AI responds by asking \"what\\'s up.\"'}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a long string\n",
    "schedule = \"There is a meeting at 8am with your product team. \\\n",
    "You will need your powerpoint presentation prepared. \\\n",
    "9am-12pm have time to work on your LangChain \\\n",
    "project which will go quickly because Langchain is such a powerful tool. \\\n",
    "At Noon, lunch at the italian resturant with a customer who is driving \\\n",
    "from over an hour away to meet you to understand the latest in AI. \\\n",
    "Be sure to bring your laptop to show the latest LLM demo.\"\n",
    "\n",
    "memory = ConversationSummaryMemory(llm=llm)\n",
    "memory.save_context({\"input\": \"Hello\"}, {\"output\": \"What's up\"})\n",
    "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "                    {\"output\": \"Cool\"})\n",
    "memory.save_context({\"input\": \"What is on the schedule today?\"}, \n",
    "                    {\"output\": f\"{schedule}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'The human greets the AI with a hello, and the AI responds by asking what\\'s up. The human replies that they\\'re just hanging, and the AI responds with \"Cool.\" The human then asks about the schedule for the day, and the AI provides a detailed itinerary including a meeting with the product team, work on the LangChain project, and a lunch meeting with a customer interested in AI.'}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "The human greets the AI with a hello, and the AI responds by asking what's up. The human replies that they're just hanging, and the AI responds with \"Cool.\" The human then asks about the schedule for the day, and the AI provides a detailed itinerary including a meeting with the product team, work on the LangChain project, and a lunch meeting with a customer interested in AI.\n",
      "Human: What would be a good demo to show?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'For the meeting with the product team, I would recommend showcasing the latest updates on the LangChain project, highlighting the new features and improvements. For the lunch meeting with the customer interested in AI, you could demonstrate a live demo of our AI chatbot in action, showcasing its natural language processing capabilities and personalized responses. This would give them a good idea of the potential applications of AI in their business.'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What would be a good demo to show?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversation Buffer Summary\n",
    "\n",
    " Same as conversation just restrict tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a long string\n",
    "schedule = \"There is a meeting at 8am with your product team. \\\n",
    "You will need your powerpoint presentation prepared. \\\n",
    "9am-12pm have time to work on your LangChain \\\n",
    "project which will go quickly because Langchain is such a powerful tool. \\\n",
    "At Noon, lunch at the italian resturant with a customer who is driving \\\n",
    "from over an hour away to meet you to understand the latest in AI. \\\n",
    "Be sure to bring your laptop to show the latest LLM demo.\"\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100)\n",
    "memory.save_context({\"input\": \"Hello\"}, {\"output\": \"What's up\"})\n",
    "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "                    {\"output\": \"Cool\"})\n",
    "memory.save_context({\"input\": \"What is on the schedule today?\"}, \n",
    "                    {\"output\": f\"{schedule}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"System: The human and AI exchange greetings and discuss the day's schedule. The AI informs the human of a morning meeting with the product team, work on the LangChain project, and a lunch meeting with a customer interested in AI. The AI emphasizes the importance of being prepared for the day's events.\"}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: The human and AI exchange greetings and discuss the day's schedule. The AI informs the human of a morning meeting with the product team, work on the LangChain project, and a lunch meeting with a customer interested in AI. The AI emphasizes the importance of being prepared for the day's events.\n",
      "Human: What would be a good demo to show?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"For the morning meeting with the product team, a demo showcasing the latest features and updates on the LangChain project would be ideal. For the lunch meeting with the customer interested in AI, a demo highlighting the capabilities of our AI technology and how it can benefit their specific needs would be impressive. It's important to tailor the demos to each audience to make a strong impact.\""
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What would be a good demo to show?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"System: The human and AI exchange greetings and discuss the day's schedule. The AI informs the human of a morning meeting with the product team, work on the LangChain project, and a lunch meeting with a customer interested in AI. The AI emphasizes the importance of being prepared for the day's events.\\nHuman: What would be a good demo to show?\\nAI: For the morning meeting with the product team, a demo showcasing the latest features and updates on the LangChain project would be ideal. For the lunch meeting with the customer interested in AI, a demo highlighting the capabilities of our AI technology and how it can benefit their specific needs would be impressive. It's important to tailor the demos to each audience to make a strong impact.\"}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
